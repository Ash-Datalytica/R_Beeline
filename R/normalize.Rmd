---
title: "Normalize"
author: "Alexey Shovkun"
date: "28 сентября 2015 г."
output: html_document
---

```{r init, echo=FALSE, message=FALSE}
#require (data.table)
require(caret) #dummyVars, featurePlot
#require(AppliedPredictiveModeling) #transparentTheme
require(Hmisc) #cut2
#require(mice)
#require(parallel) #detectCores()
#require(doSNOW)

eval(parse('common.R',encoding = "UTF-8"))
trellis.par.set(caretTheme())
```

```{r loadData, echo=FALSE}
dfTrainCM <- readRDS("../data/train_ConstMedian.rds")
dfTestCM <- readRDS("../data/test_ConstMedian.rds")
whichNumeric <- sapply(dfTrainCM, class)=="numeric" # Булева маска числовых столбцов
colNumeric <- colnames(dfTrainCM)[which(whichNumeric)] # Список имен числовых столбцов

```

Необходимо нормализовать значения параметров типа numeric. Рассмотрим 2 варианта нормализации:

1. все переменные нормализуем линейно. Либо в диапазон [0,1], либо [-1,1].
2. Подбираем разные варианты нормализации для разных переменных. в том чиисле и нелинейную нормализацию.

# Линейная нормализация

```{r normLinear, echo=FALSE}
preNormLinear <- preProcess (dfTrainCM[colNumeric], method=c("range") )
#preNormLinear$ranges
dfNormNumeric <- predict(preNormLinear, dfTrainCM[colNumeric])
summary (dfNormNumeric)  

# NR означает линейно нормализованные данные (NormRange)
dfTrainCMNR <- dfTrainCM
dfTrainCMNR[colNumeric] <- dfNormNumeric
#class(dfTrainCMNR[,1])

saveRDS (dfTrainCMNR, "../data/train_ConstMedianRange.rds")

## аналогично обрабатываем тестовые данные
dfTestCMNR <- dfTestCM
dfTestCMNR[colNumeric] <- predict(preNormLinear, dfTestCM[colNumeric])
saveRDS (dfTestCMNR, "../data/test_ConstMedianRange.rds")
```

Посмотрим графически на результаты нормализации на 5% данных.

```{r normLinearScatter, echo=FALSE, warning=FALSE, message = FALSE, fig.width=9, fig.height=9, cache=TRUE }
set.seed(20150926)
inEDA <- createDataPartition(dfTrainCM$y, p = 0.05, list = FALSE, times = 1)
#ncol(dfNormNumeric) #41 шт
myPlotFeatures (dfNormNumeric[inEDA,], dfTrainCM$y, featuresInGraph = 6 )

```

# Нелинейная нормализация (Yeo Johnson, range)

Нормализуем все числовые переменные методом Yeo Johnson, а затем результат нормализуем в диапазон [0,1]
```{r normYeoJohnsonRange, echo=FALSE}
preNormYJR <- preProcess (dfTrainCM[colNumeric], method=c("YeoJohnson", "range") )
dfNormYJR <- predict(preNormYJR, dfTrainCM[colNumeric])

# NYJR означает нормалтзацию YeoHohnson с последующим масштабированием [0,1] (NormYeaJohnsonRange)
dfTrainCMYJR <- dfTrainCM
dfTrainCMYJR[colNumeric] <- dfNormYJR
#class(dfTrainCMNR[,1])

saveRDS (dfTrainCMYJR, "../data/train_ConstMedianYeoJohnsonRange.rds")

## аналогично обрабатываем тестовые данные
dfTestCMYJR <- dfTestCM
dfTestCMYJR[colNumeric] <- predict(preNormYJR, dfTestCM[colNumeric])
saveRDS (dfTestCMYJR, "../data/test_ConstMedianYeoJohnsonRange.rds")
```

Посмотрим графически на результаты нормализации на 5% данных.

```{r normYJRScatter, echo=FALSE, warning=FALSE, message = FALSE, fig.width=9, fig.height=9, cache=TRUE }
set.seed(20150926)
inEDA <- createDataPartition(dfTrainCM$y, p = 0.05, list = FALSE, times = 1)
myPlotFeatures (dfNormYJR[inEDA,], dfTrainCM$y, featuresInGraph = 6 )
```

# Нелинейная нормализация (Yeo Johnson)

Нормализуем все числовые переменные методом Yeo Johnson, а затем результат нормализуем в диапазон [0,1]
```{r normYeoJohnson, echo=FALSE}
preNormYJ <- preProcess (dfTrainCM[colNumeric], method=c("YeoJohnson") )
dfNormYJ <- predict(preNormYJ, dfTrainCM[colNumeric])

# NYJR означает нормалтзацию YeoHohnson с последующим масштабированием [0,1] (NormYeaJohnsonRange)
dfTrainCMYJ <- dfTrainCM
dfTrainCMYJ[colNumeric] <- dfNormYJ
#class(dfTrainCMNR[,1])

saveRDS (dfTrainCMYJ, "../data/train_ConstMedianYeoJohnson.rds")

## аналогично обрабатываем тестовые данные
dfTestCMYJ <- dfTestCM
dfTestCMYJ[colNumeric] <- predict(preNormYJ, dfTestCM[colNumeric])
saveRDS (dfTestCMYJ, "../data/test_ConstMedianYeoJohnson.rds")
```

Посмотрим графически на результаты нормализации на 5% данных.

```{r normYJScatter, echo=FALSE, warning=FALSE, message = FALSE, fig.width=9, fig.height=9, cache=TRUE }
set.seed(20150926)
inEDA <- createDataPartition(dfTrainCMYJ$y, p = 0.05, list = FALSE, times = 1)
#ncol(dfNormNumeric) #41 шт
myPlotFeatures (dfNormYJ[inEDA,], dfTrainCMYJ$y, featuresInGraph = 6 )

```

# Выборочная нормализация

```{r normSelected, echo=FALSE}
# параметры с отрицательными начениями
colNegative <- colnames(dfTrainCM[colNumeric]) [apply (dfTrainCM[colNumeric], 2, min)<0]
# параметры с явно выраженными выделяющимия значениями (визуально)
colOutliers <- c("x8", "x13", "x23", "x25", "x26", "x28", "x29", "x30", "x32", 
                 "x36", "x37", "x38", "x39", "x40", "x43", "x44", "x55", "x61")
# параметры с НЕявно выраженными выделяющимия значениями (визуально)
colProbableOutliers <- c("x34", "x35", "x45", "x46", "x47", "x48", "x49", "x50", "x57", "x58", "x59")

# Подготовим 2 варианта нормализации.
# В первом варианте подвергнем гиперболическому тангенсу только отрицательные параметры и
# параметры с явно выраженными выбросами
colTanhSure <- union(colNegative, colOutliers)
# остальные будем нормализовать линейно
colNotTanhSure <- setdiff(colNumeric, colTanhSure)

# Тангенс. хотим, чтобы среднее переменной после нормализации была = 0,5 
# Для некоторых параметров среднее дает более равномерные картинки, чем медиана.
dfTanhSure <- as.data.frame(apply(dfTrainCM[colTanhSure], 2, function(col){normalizeTanh(col,mode="median", targetValue = 0.5)}))
#apply (dfTanhSure, 2, median) # все = 0.5
# Линейно
preSelectedLinear <- preProcess (dfTrainCM[colNotTanhSure], method=c("range") )
dfSelectedLinear <- predict(preSelectedLinear, dfTrainCM[colNotTanhSure])

# Собираем результат CMSS = ConstMedianSelectedSure
dfTrainCMSS <- dfTrainCM
dfTrainCMSS[colTanhSure] <- dfTanhSure
dfTrainCMSS[colNotTanhSure] <- dfSelectedLinear
saveRDS (dfTrainCMSS, "../data/train_ConstMedianSelectedSure.rds")

## аналогично обрабатываем тестовые данные
dfTestCMSS <- dfTestCM
dfTestCMSS[colTanhSure] <- as.data.frame(apply(
    dfTestCM[colTanhSure], 2, 
    function(col){normalizeTanh(col,mode="median", targetValue = 0.5)}))
dfTestCMSS[colNotTanhSure] <- predict(preSelectedLinear, dfTestCM[colNotTanhSure])
saveRDS (dfTestCMSS, "../data/test_ConstMedianSelectedSure.rds")

```

Нормализация гиперболическим тангенсом: **`r colTanhSure`**.

Линейная нормализация: **`r colNotTanhSure`**.

Посмотрим графически на результаты нормализации на 5% данных.

```{r normSelectedSureScatter, echo=FALSE, warning=FALSE, message = FALSE, fig.width=9, fig.height=9, cache=TRUE }
set.seed(20150926)
inEDA <- createDataPartition(dfTrainCMSS$y, p = 0.05, list = FALSE, times = 1)
#ncol(dfNormNumeric) #41 шт
myPlotFeatures (dfTrainCMSS[inEDA,union(colTanhSure, colNotTanhSure)], dfTrainCMSS$y, featuresInGraph = 6 )

```

#TODO
 - Некоторые параметры нормализовывать гипертангенсом через серденее (х38)

